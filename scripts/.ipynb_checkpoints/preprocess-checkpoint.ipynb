{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import math, random, sys\n",
    "import cPickle as pickle\n",
    "import argparse\n",
    "\n",
    "from fast_jtnn import *\n",
    "import rdkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorize(smiles, assm=False):\n",
    "    try: #added\n",
    "        mol_tree = MolTree(smiles)\n",
    "        mol_tree.recover()\n",
    "        if assm:\n",
    "            mol_tree.assemble()\n",
    "            for node in mol_tree.nodes:\n",
    "                if node.label not in node.cands:\n",
    "                    node.cands.append(node.label)\n",
    "\n",
    "        del mol_tree.mol\n",
    "        for node in mol_tree.nodes:\n",
    "            del node.mol\n",
    "            del node.clique\n",
    "\n",
    "        return mol_tree\n",
    "    except: #added\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorize_pair(smiles_pair):\n",
    "    mol_tree0 = tensorize(smiles_pair[0], assm=True) #added\n",
    "    #mol_tree0 = tensorize(smiles_pair[0], assm=False)\n",
    "    #mol_tree1 = tensorize(smiles_pair[1], assm=False) #added\n",
    "    mol_tree1 = tensorize(smiles_pair[1], assm=True)\n",
    "    return (mol_tree0, mol_tree1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually set args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncpu = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = '/home/rgur/CS6250_project/g2g/polymers_trial2/data/trial_train_1337.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually run main for pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = rdkit.RDLogger.logger() \n",
    "lg.setLevel(rdkit.RDLogger.CRITICAL)\n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--train', required=True)\n",
    "#parser.add_argument('--mode', type=str, default='pair')\n",
    "#parser.add_argument('--ncpu', type=int, default=8)\n",
    "#args = parser.parse_args()\n",
    "\n",
    "#ncpu = args.ncpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(ncpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = args.train\n",
    "#if args.mode == 'pair':\n",
    "    #dataset contains molecule pairs\n",
    "with open(train) as f:\n",
    "    data = [line.strip(\"\\r\\n \").split()[:2] for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1337"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#all_data = pool.map(tensorize_pair, data)\n",
    "all_data1 = pool.map(tensorize_pair, data) #added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1337"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [i for i in all_data1 if None not in i] #added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_splits = len(all_data) / 2000 #added\n",
    "num_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_splits == 0: #added\n",
    "    num_splits = 1 #added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1226"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = (len(all_data) + num_splits - 1) / num_splits\n",
    "le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_id in xrange(num_splits):\n",
    "    st = split_id * le\n",
    "    sub_data = all_data[st : st + le]\n",
    "\n",
    "    with open('tensors-%d.pkl' % split_id, 'wb') as f:\n",
    "        pickle.dump(sub_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# elif args.mode == 'single':\n",
    "#     #dataset contains single molecules\n",
    "#     with open(args.train) as f:\n",
    "#         data = [line.strip(\"\\r\\n \").split()[0] for line in f]\n",
    "\n",
    "#     all_data = pool.map(tensorize, data)\n",
    "#     num_splits = len(data) / 10000\n",
    "\n",
    "#     le = (len(all_data) + num_splits - 1) / num_splits\n",
    "\n",
    "#     for split_id in xrange(num_splits):\n",
    "#         st = split_id * le\n",
    "#         sub_data = all_data[st : st + le]\n",
    "\n",
    "#         with open('tensors-%d.pkl' % split_id, 'wb') as f:\n",
    "#             pickle.dump(sub_data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manually run main for single"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually set args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = '/home/rgur/CS6250_project/g2g/polymers_trial2/data/trial_test_899.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args.train = train #added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train) as f:\n",
    "    data = [line.strip(\"\\r\\n \").split()[0] for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data = pool.map(tensorize, data)\n",
    "all_data1 = pool.map(tensorize, data) #added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [i for i in all_data1 if i is not None] #added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = len(all_data) / 10000 #added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_splits == 0: #added\n",
    "    num_splits = 1 #added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = (len(all_data) + num_splits - 1) / num_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "607"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split_id in xrange(num_splits):\n",
    "    st = split_id * le\n",
    "    sub_data = all_data[st : st + le]\n",
    "\n",
    "    with open('tensors-%d.pkl' % split_id, 'wb') as f:\n",
    "        pickle.dump(sub_data, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cse6250)",
   "language": "python",
   "name": "cse6250"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
